const db = require('../config/database');
const ContentModerationService = require('../src/services/ContentModerationService');
const path = require('path');
const fs = require('fs');

async function testUploadFlow() {
    console.log('üß™ Testing End-to-End Upload Flow with New Configuration System...\n');
    
    try {
        const service = new ContentModerationService(db);
        
        // Find a test image to use
        const uploadsDir = '/Users/programmer/Projects/musenest/public/uploads';
        let testImagePath = null;
        
        // Look for any existing image in uploads
        if (fs.existsSync(uploadsDir)) {
            const models = fs.readdirSync(uploadsDir).filter(item => 
                fs.statSync(path.join(uploadsDir, item)).isDirectory()
            );
            
            for (const model of models) {
                const originalsDir = path.join(uploadsDir, model, 'originals');
                if (fs.existsSync(originalsDir)) {
                    const images = fs.readdirSync(originalsDir).filter(file => 
                        /\.(jpg|jpeg|png|webp)$/i.test(file)
                    );
                    
                    if (images.length > 0) {
                        testImagePath = path.join(originalsDir, images[0]);
                        console.log(`üìÅ Found test image: ${testImagePath}`);
                        break;
                    }
                }
            }
        }
        
        if (!testImagePath) {
            console.log('‚ö†Ô∏è No test images found in uploads directory');
            console.log('   Creating a dummy test scenario instead...\n');
            
            // Test with simulated analysis results
            await testSimulatedAnalysis(service);
            return;
        }
        
        // Test different usage intents
        const testScenarios = [
            { usageIntent: 'public_site', modelId: 1, description: 'Public Site (Conservative)' },
            { usageIntent: 'paysite', modelId: 1, description: 'Paysite (Moderate)' },
            { usageIntent: 'store', modelId: 1, description: 'Store (Liberal)' }
        ];
        
        for (const scenario of testScenarios) {
            console.log(`\\nüéØ Testing: ${scenario.description}`);
            console.log(`   Usage Intent: ${scenario.usageIntent}`);
            console.log(`   Model ID: ${scenario.modelId}`);
            
            try {
                // Test the analysis with configuration
                console.log('   üìä Loading configuration...');
                const config = await service.loadAnalysisConfiguration(scenario.usageIntent, scenario.modelId);
                
                if (config) {
                    console.log(`   ‚úÖ Config loaded: v${config.version || 1}`);
                    console.log(`   üìà Thresholds: approve<${config.scoring_config.thresholds.auto_approve_under}%, flag>${config.scoring_config.thresholds.auto_flag_over}%`);
                    console.log(`   üîç Detection: breast=${config.detection_config.nudenet_components.breast_detection}, face=${config.detection_config.nudenet_components.face_detection}`);
                } else {
                    console.log('   ‚ùå Failed to load configuration');
                    continue;
                }
                
                // Simulate the analysis call (since we might not have EC2 API available)
                console.log('   üîÑ Simulating analysis call...');
                
                // Create mock analysis result
                const mockAnalysis = {
                    detected_parts: { 
                        'BREAST_EXPOSED': 65.0, 
                        'FACE_DETECTED': 90.0 
                    },
                    part_locations: {},
                    nudity_score: 58,
                    has_nudity: true,
                    face_count: 1,
                    min_detected_age: 25,
                    underage_detected: false,
                    contains_children: false,
                    image_description: { description: 'Test image analysis' },
                    description_text: 'Test image for analysis',
                    description_tags: [],
                    final_risk_score: 58,
                    risk_level: 'medium'
                };
                
                // Apply moderation rules with the new system
                console.log('   ‚öñÔ∏è Applying moderation rules...');
                const moderationResult = await service.applyModerationRules(
                    mockAnalysis, 
                    scenario.usageIntent, 
                    scenario.modelId
                );
                
                console.log('   üìã Results:');
                console.log(`     üìä Original score: ${mockAnalysis.nudity_score}% ‚Üí Weighted: ${moderationResult.weighted_nudity_score || moderationResult.nudity_score}%`);
                console.log(`     üè∑Ô∏è Status: ${moderationResult.moderation_status}`);
                console.log(`     üö© Flagged: ${moderationResult.flagged}`);
                console.log(`     üëÅÔ∏è Review Required: ${moderationResult.human_review_required}`);
                console.log(`     üìç Final Location: ${moderationResult.final_location}`);
                
                // Show how the weighting affected the decision
                const originalWouldBe = mockAnalysis.nudity_score > config.scoring_config.thresholds.auto_flag_over ? 'flagged' : 'approved';
                const newDecision = moderationResult.moderation_status;
                
                if (originalWouldBe !== newDecision) {
                    console.log(`     üîÑ Decision Changed: Old system would have ${originalWouldBe}, new system: ${newDecision}`);
                } else {
                    console.log(`     ‚úÖ Decision Consistent: Both systems would ${newDecision}`);
                }
                
            } catch (error) {
                console.log(`   ‚ùå Error: ${error.message}`);
            }
        }
        
        console.log('\\n‚úÖ End-to-End Test Complete!');
        
    } catch (error) {
        console.error('‚ùå Test failed:', error);
        console.error(error.stack);
    } finally {
        process.exit(0);
    }
}

async function testSimulatedAnalysis(service) {
    console.log('üé≠ Running Simulated Analysis Tests...\n');
    
    const scenarios = [
        {
            name: 'Family Photo',
            analysis: {
                detected_parts: { 'FACE_DETECTED': 95.0 },
                nudity_score: 2,
                has_nudity: false,
                underage_detected: false,
                contains_children: false
            }
        },
        {
            name: 'Fashion Photo',
            analysis: {
                detected_parts: { 'BREAST_EXPOSED': 35.0, 'FACE_DETECTED': 85.0 },
                nudity_score: 28,
                has_nudity: true,
                underage_detected: false,
                contains_children: false
            }
        },
        {
            name: 'Adult Content',
            analysis: {
                detected_parts: { 'GENITALIA': 88.0, 'BREAST_EXPOSED': 75.0 },
                nudity_score: 84,
                has_nudity: true,
                underage_detected: false,
                contains_children: false
            }
        }
    ];
    
    for (const scenario of scenarios) {
        console.log(`\\nüì∏ Scenario: ${scenario.name}`);
        
        for (const intent of ['public_site', 'paysite']) {
            const result = await service.applyModerationRules(scenario.analysis, intent, null);
            
            console.log(`  ${intent}:`);
            console.log(`    üìä ${scenario.analysis.nudity_score}% ‚Üí ${result.weighted_nudity_score || result.nudity_score}%`);
            console.log(`    üè∑Ô∏è ${result.moderation_status} (${result.flagged ? 'flagged' : 'approved'})`);
        }
    }
}

testUploadFlow();